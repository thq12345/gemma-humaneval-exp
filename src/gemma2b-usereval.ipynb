{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:39:54.367455900Z",
     "start_time": "2024-03-31T20:39:48.742455700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\danny\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset, load_metric\n",
    "from huggingface_hub import login\n",
    "import re\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e05dad5de0e2467994dacadbf5255853"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"cpu\")\n",
    "\n",
    "# Assuming CUDA is available, adjust if necessary\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:40:03.236491700Z",
     "start_time": "2024-03-31T20:39:54.356458500Z"
    }
   },
   "id": "9e6cff73189ad01e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       task_id                                             prompt  \\\n0  HumanEval/0  from typing import List\\n\\n\\ndef has_close_ele...   \n1  HumanEval/1  from typing import List\\n\\n\\ndef separate_pare...   \n2  HumanEval/2  \\n\\ndef truncate_number(number: float) -> floa...   \n3  HumanEval/3  from typing import List\\n\\n\\ndef below_zero(op...   \n4  HumanEval/4  from typing import List\\n\\n\\ndef mean_absolute...   \n\n                                  canonical_solution  \\\n0      for idx, elem in enumerate(numbers):\\n    ...   \n1      result = []\\n    current_string = []\\n    ...   \n2                              return number % 1.0\\n   \n3      balance = 0\\n\\n    for op in operations:\\n...   \n4      mean = sum(numbers) / len(numbers)\\n    re...   \n\n                                                test              entry_point  \n0  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...       has_close_elements  \n1  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...    separate_paren_groups  \n2  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...          truncate_number  \n3  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...               below_zero  \n4  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...  mean_absolute_deviation  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_id</th>\n      <th>prompt</th>\n      <th>canonical_solution</th>\n      <th>test</th>\n      <th>entry_point</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HumanEval/0</td>\n      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>has_close_elements</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HumanEval/1</td>\n      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n      <td>result = []\\n    current_string = []\\n    ...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>separate_paren_groups</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HumanEval/2</td>\n      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n      <td>return number % 1.0\\n</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>truncate_number</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HumanEval/3</td>\n      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>below_zero</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HumanEval/4</td>\n      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>mean_absolute_deviation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"openai_humaneval\")\n",
    "humaneval_df = dataset['test'].to_pandas()\n",
    "humaneval_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:40:06.070350100Z",
     "start_time": "2024-03-31T20:40:03.237491500Z"
    }
   },
   "id": "20d31b636bbb190d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \n",
    "\"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    ..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79e023a20b5196d0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def remove_triple_quotes(text: str) -> str:\n",
    "    # Pattern to match triple double quotes and everything in between\n",
    "    pattern_double_quotes = r'\"\"\"(.*?)\"\"\"'\n",
    "    # Pattern to match triple single quotes and everything in between\n",
    "    pattern_single_quotes = r\"'''(.*?)'''\"\n",
    "    \n",
    "    # Remove triple double quotes and their contents\n",
    "    text_without_double_quotes = re.sub(pattern_double_quotes, '', text, flags=re.DOTALL)\n",
    "    # Remove triple single quotes and their contents\n",
    "    text_without_any_quotes = re.sub(pattern_single_quotes, '', text_without_double_quotes, flags=re.DOTALL)\n",
    "    \n",
    "    return text_without_any_quotes\n",
    "\n",
    "def extract_first_function(text):\n",
    "    # This regex pattern is designed to match a Python function definition.\n",
    "    # It looks for patterns that start with 'def' followed by any valid function name and parameters,\n",
    "    # and then captures until it finds a non-indented line, assuming it's the end of the function.\n",
    "    pattern = r\"(def .+?\\):)(\\n\\s+.+)+\"\n",
    "    \n",
    "    # Using re.DOTALL to make '.' match newlines as well.\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # Returning the matched function.\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return \"No function found.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:40:06.070350100Z",
     "start_time": "2024-03-31T20:40:06.060350600Z"
    }
   },
   "id": "6a2ec05bba7a3060"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def execute_code(generated_code, test, entry_point):\n",
    "    def target(local_vars):\n",
    "        try:\n",
    "            # define Gemma-generated code\n",
    "            exec(generated_code, globals(), local_vars)\n",
    "            \n",
    "            # define test\n",
    "            updated_test_code = test.replace('candidate', entry_point)\n",
    "            exec(updated_test_code, globals(), local_vars)\n",
    "            # run test\n",
    "            exec(f'check({entry_point})', globals(), local_vars)\n",
    "            \n",
    "            local_vars[\"test_passed\"] = True\n",
    "        except AssertionError:\n",
    "            local_vars[\"test_passed\"] = False\n",
    "        except Exception as e:\n",
    "            print(f\"Error during execution: {e}\")\n",
    "            local_vars[\"test_passed\"] = False\n",
    "\n",
    "    local_vars = {}\n",
    "    # Remove triple quotes if needed\n",
    "    print('generated code is:', generated_code)\n",
    "    generated_code = remove_triple_quotes(generated_code)\n",
    "    test_thread = threading.Thread(target=target, args=(local_vars,))\n",
    "    test_thread.start()\n",
    "\n",
    "    # Wait for the specified timeout\n",
    "    test_thread.join(timeout=3)\n",
    "    if test_thread.is_alive():\n",
    "        print(\"Execution timed out\")\n",
    "        return False\n",
    "\n",
    "    # Return the result of the test execution\n",
    "    return local_vars.get(\"test_passed\", False)\n",
    "\n",
    "\n",
    "def predict_and_evaluate(task):\n",
    "    prompt = ('Please provide as concise solution as possible, do NOT include duplicate code. '\n",
    "              'Stop when you realize code is duplicating, provide python code ONLY, no text instructions'\n",
    "              'Here is the question: \\n') + task[\"prompt\"]\n",
    "    #prompt = task[\"prompt\"]\n",
    "    test_code = task[\"test\"]\n",
    "    entry_point = task[\"entry_point\"]\n",
    "    \n",
    "    # Generate input_ids\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate code using the model\n",
    "    outputs = model.generate(input_ids, max_length=1000)\n",
    "    generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_code = generated_code.split(\"Answer:\", 1)[1] if \"Answer:\" in generated_code else generated_code\n",
    "    generated_code = extract_first_function(generated_code)\n",
    "    # Execute generated code and compare outputs\n",
    "    try:\n",
    "        result = execute_code(generated_code, test_code, entry_point)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during execution: {e}\")\n",
    "        result = False\n",
    "    \n",
    "    print('the result is', result)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:40:06.093031200Z",
     "start_time": "2024-03-31T20:40:06.068349700Z"
    }
   },
   "id": "ab2f20af49463c9b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "humaneval_df = humaneval_df.drop(index=[6])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:40:06.174006400Z",
     "start_time": "2024-03-31T20:40:06.085032600Z"
    }
   },
   "id": "226463cb9dad4da2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\anaconda3\\envs\\transformer-final-project\\lib\\site-packages\\transformers\\models\\gemma\\modeling_gemma.py:573: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start_of_turn>user\n",
      "Generate a Python function that multiplies two numbers <end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of_turn>user\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "<end_of_turn>\n",
      "<start_of\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"<start_of_turn>user\n",
    "Generate a Python function that multiplies two numbers <end_of_turn>\n",
    "<start_of_turn>model\"\"\"\n",
    "tokenized_prompt = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(tokenized_prompt, max_length=100)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:42:35.865312100Z",
     "start_time": "2024-03-31T20:42:17.216604900Z"
    }
   },
   "id": "7b865bf826483d96"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# results = []\n",
    "# # Assuming `df` is your DataFrame\n",
    "# for index, row in humaneval_df.iloc[[46]].iterrows():\n",
    "#     task = {\n",
    "#         \"prompt\": row[\"prompt\"],\n",
    "#         \"test\": row[\"test\"],\n",
    "#         \"entry_point\": row[\"entry_point\"]\n",
    "#     }\n",
    "#     print(f\"executing {index}\")\n",
    "#     results.append(predict_and_evaluate(task))\n",
    "# \n",
    "# \n",
    "# # Calculate and print the metric, e.g., accuracy\n",
    "# accuracy = sum(results) / len(results)\n",
    "# print(f\"Model Accuracy on HumanEval: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:42:35.908567100Z",
     "start_time": "2024-03-31T20:42:35.866785700Z"
    }
   },
   "id": "2999336863debd0c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:42:35.921769300Z",
     "start_time": "2024-03-31T20:42:35.881790400Z"
    }
   },
   "id": "4e6856e567e354ff"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:42:35.922767300Z",
     "start_time": "2024-03-31T20:42:35.896642400Z"
    }
   },
   "id": "29b799683c186218"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "74c9b46ac4213c29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
